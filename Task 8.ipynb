{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6426fa-e182-4a48-a589-e3f19f6df177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Math  Science  English  Pass\n",
      "0    85       88       78     1\n",
      "1    70       65       80     0\n",
      "2    90       95       88     1\n",
      "3    60       55       58     0\n",
      "4    75       70       76     1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Math': [85, 70, 90, 60, 75, 88, 45, 95],\n",
    "    'Science': [88, 65, 95, 55, 70, 85, 50, 92],\n",
    "    'English': [78, 80, 88, 58, 76, 90, 52, 85],\n",
    "    'Pass': [1, 0, 1, 0, 1, 1, 0, 1]  \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b11c66",
   "metadata": {},
   "source": [
    " 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc3c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create new features\n",
    "df['Total_Score'] = df['Math'] + df['Science'] + df['English']\n",
    "df['Average_Score'] = df['Total_Score'] / 3\n",
    "\n",
    "\n",
    "#  Prepare X and y\n",
    "\n",
    "\n",
    "# Features and target\n",
    "X = df[['Math', 'Science', 'English', 'Total_Score', 'Average_Score']]\n",
    "y = df['Pass']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540ffdd",
   "metadata": {},
   "source": [
    "3. Model & GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid (without None)\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,cv=2, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a8a58",
   "metadata": {},
   "source": [
    "\n",
    "4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation Report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, labels=[0, 1], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204c35d",
   "metadata": {},
   "source": [
    "Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb72ee7-a663-4f97-8e12-a050cd5aef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows:\n",
      "    Transaction ID  Amount    Type  Is Fraud\n",
      "0            1001    1500  credit         0\n",
      "1            1002     250   debit         0\n",
      "2            1003    7600  credit         1\n",
      "3            1004     120   debit         0\n",
      "4            1005    9500  credit         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 2. Load dataset\n",
    "df = pd.read_csv(\"fraud_detection.csv\")\n",
    "\n",
    "# 3. Preview the data\n",
    "print(\"Initial rows:\\n\", df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd217e",
   "metadata": {},
   "source": [
    "1. Load & Preprocess the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42deddf5-990b-4d35-a90f-42c14638cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      " Transaction ID    0\n",
      "Amount            0\n",
      "Type              0\n",
      "Is Fraud          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  Check for missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "#  Drop missing rows if any\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c793041e-1a8f-4893-be53-b8bc7ebc5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Encode 'Type' using Label Encoding \n",
    "le = LabelEncoder()\n",
    "df['Type_encoded'] = le.fit_transform(df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35923b4-d8af-4868-9d59-dd7440a58e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop 'Transaction ID' (not useful for prediction)\n",
    "df.drop('Transaction ID', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638a53c-68af-44bc-a438-912c96230288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after preprocessing:\n",
      "    Amount    Type  Is Fraud  Type_encoded\n",
      "0    1500  credit         0             0\n",
      "1     250   debit         0             1\n",
      "2    7600  credit         1             0\n",
      "3     120   debit         0             1\n",
      "4    9500  credit         1             0\n",
      "\n",
      "Dataset shape: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "#  Final Data Check\n",
    "print(\"\\nData after preprocessing:\\n\", df.head())\n",
    "print(\"\\nDataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0abd61",
   "metadata": {},
   "source": [
    " 2. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50106c9a-4a47-4fcb-924f-377c5c2066cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Amount  Is Fraud  Amount_log  Is_Large_Amount  Amount_Category_encoded\n",
      "0    1500         0    7.313887                0                        2\n",
      "1     250         0    5.525453                0                        1\n",
      "2    7600         1    8.936035                1                        0\n",
      "3     120         0    4.795791                0                        1\n",
      "4    9500         1    9.159152                1                        0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature 1: Log transform\n",
    "df['Amount_log'] = np.log1p(df['Amount'])\n",
    "\n",
    "# Feature 2: Binary large amount flag\n",
    "df['Is_Large_Amount'] = df['Amount'].apply(lambda x: 1 if x > 5000 else 0)\n",
    "\n",
    "# Feature 3: Amount category (Low/Medium/High)\n",
    "def categorize_amount(x):\n",
    "    if x < 1000:\n",
    "        return 'Low'\n",
    "    elif x < 5000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['Amount_Category'] = df['Amount'].apply(categorize_amount)\n",
    "df['Amount_Category_encoded'] = LabelEncoder().fit_transform(df['Amount_Category'])\n",
    "\n",
    "# Safely drop unnecessary columns\n",
    "df.drop(['Transaction ID', 'Type', 'Amount_Category'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Final Data Preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b4f63",
   "metadata": {},
   "source": [
    "3. Train a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5caf395-aeca-4a47-bb13-2c7d5d15f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#  Define Features and Target\n",
    "X = df.drop('Is Fraud', axis=1)  # Features\n",
    "y = df['Is Fraud']               # Target\n",
    "\n",
    "#  Split the data (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "#  Train the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#  Predict on test data\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ac47c",
   "metadata": {},
   "source": [
    "4. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13502e6-4546-4a5e-b741-e4a51ad1f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[2 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, labels=[0, 1], zero_division=0))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=[0, 1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
